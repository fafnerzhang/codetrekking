#!/usr/bin/env python3
"""
FIT File Data Structure Analysis and Summary
"""
import fitparse
from collections import defaultdict, Counter
import pandas as pd
from pathlib import Path


def analyze_fit_file(fit_file_path):
    """Analyze the complete structure of a FIT file"""
    
    print(f"ğŸ” Analyzing FIT file: {fit_file_path}")
    print("=" * 80)
    
    fit = fitparse.FitFile(fit_file_path)
    
    # Analysis results dictionary
    analysis = {
        'session': {'count': 0, 'fields': [], 'field_details': {}},
        'record': {'count': 0, 'fields': [], 'field_details': {}},
        'lap': {'count': 0, 'fields': [], 'field_details': {}}
    }
    
    # 1. Analyze Session data
    print("\nğŸ“Š Session Data Analysis")
    print("-" * 50)
    
    sessions = list(fit.get_messages('session'))
    analysis['session']['count'] = len(sessions)
    
    if sessions:
        session = sessions[0]
        for field in session.fields:
            if field.value is not None:
                field_info = {
                    'name': field.name,
                    'type': type(field.value).__name__,
                    'units': field.units or '',
                    'sample_value': str(field.value)[:50] + ('...' if len(str(field.value)) > 50 else ''),
                    'data_category': 'session'
                }
                analysis['session']['fields'].append(field.name)
                analysis['session']['field_details'][field.name] = field_info
    
    print(f"ğŸ“ˆ Session data count: {analysis['session']['count']} records")
    print(f"ğŸ·ï¸  Session field count: {len(analysis['session']['fields'])} fields")
    
    # 2. Analyze Record data
    print("\nğŸƒ Record Data Analysis")
    print("-" * 50)
    
    records = list(fit.get_messages('record'))
    analysis['record']['count'] = len(records)
    
    # Count record field occurrence frequency
    field_frequency = {}
    for record in records:
        for field in record.fields:
            if field.value is not None:
                if field.name not in field_frequency:
                    field_frequency[field.name] = {
                        'count': 0,
                        'type': type(field.value).__name__,
                        'units': field.units or '',
                        'sample_value': str(field.value)[:50] + ('...' if len(str(field.value)) > 50 else '')
                    }
                field_frequency[field.name]['count'] += 1
    
    for field_name, info in field_frequency.items():
        field_info = {
            'name': field_name,
            'type': info['type'],
            'units': info['units'],
            'sample_value': info['sample_value'],
            'frequency': f"{info['count']}/{analysis['record']['count']}",
            'percentage': f"{info['count']/analysis['record']['count']*100:.1f}%",
            'data_category': 'record'
        }
        analysis['record']['fields'].append(field_name)
        analysis['record']['field_details'][field_name] = field_info
    
    print(f"ğŸ“ˆ Record data count: {analysis['record']['count']} records")
    print(f"ğŸ·ï¸  Record field count: {len(analysis['record']['fields'])} fields")
    
    # 3. Analyze Lap data
    print("\nğŸ Lap Data Analysis")
    print("-" * 50)
    
    laps = list(fit.get_messages('lap'))
    analysis['lap']['count'] = len(laps)
    
    if laps:
        lap = laps[0]
        for field in lap.fields:
            if field.value is not None:
                field_info = {
                    'name': field.name,
                    'type': type(field.value).__name__,
                    'units': field.units or '',
                    'sample_value': str(field.value)[:50] + ('...' if len(str(field.value)) > 50 else ''),
                    'data_category': 'lap'
                }
                analysis['lap']['fields'].append(field.name)
                analysis['lap']['field_details'][field.name] = field_info
    
    print(f"ğŸ“ˆ Lap data count: {analysis['lap']['count']} records")
    print(f"ğŸ·ï¸  Lap field count: {len(analysis['lap']['fields'])} fields")
    
    return analysis


def create_summary_tables(analysis):
    """Create data summary tables"""
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ FIT File Data Structure Summary Table")
    print("=" * 80)
    
    # 1. Data type overview table
    overview_data = []
    for data_type in ['session', 'record', 'lap']:
        overview_data.append({
            'Data Type': data_type.upper(),
            'Record Count': analysis[data_type]['count'],
            'Field Count': len(analysis[data_type]['fields']),
            'Description': {
                'session': 'Exercise summary information (overall statistics for the entire workout)',
                'record': 'Real-time recorded data (detailed measurements per second)',
                'lap': 'Segment recorded data (statistics per kilometer or manual segment)'
            }[data_type]
        })
    
    overview_df = pd.DataFrame(overview_data)
    print("\nğŸ“Š Data Type Overview:")
    print(overview_df.to_string(index=False))
    
    # 2. Important field classification table
    important_fields = {
        'session': ['timestamp', 'start_time', 'sport', 'sub_sport', 'total_distance', 
                   'total_timer_time', 'total_calories', 'avg_heart_rate', 'max_heart_rate', 
                   'enhanced_avg_speed'],
        'record': ['timestamp', 'position_lat', 'position_long', 'distance', 'enhanced_speed', 
                  'enhanced_altitude', 'heart_rate', 'cadence', 'vertical_oscillation', 
                  'stance_time'],
        'lap': ['timestamp', 'start_time', 'total_distance', 'total_timer_time', 
               'avg_heart_rate', 'max_heart_rate', 'enhanced_avg_speed']
    }
    
    # 3. å„é¡å‹è©³ç´°æ¬„ä½è¡¨
    for data_type in ['session', 'record', 'lap']:
        print(f"\nğŸ“ {data_type.upper()} æ¬„ä½è©³ç´°è¡¨:")
        
        field_data = []
        for field_name in analysis[data_type]['fields']:
            field_info = analysis[data_type]['field_details'][field_name]
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºé‡è¦æ¬„ä½
            is_important = field_name in important_fields.get(data_type, [])
            
            row = {
                'æ¬„ä½åç¨±': field_name,
                'é‡è¦æ€§': 'ğŸŒŸ é‡è¦' if is_important else 'ğŸ“‹ ä¸€èˆ¬',
                'è³‡æ–™é¡å‹': field_info['type'],
                'å–®ä½': field_info['units'],
                'ç¯„ä¾‹å€¼': field_info['sample_value']
            }
            
            # Record é¡å‹å¢åŠ é »ç‡è³‡è¨Š
            if data_type == 'record':
                row['å‡ºç¾é »ç‡'] = field_info.get('frequency', '')
                row['ç™¾åˆ†æ¯”'] = field_info.get('percentage', '')
            
            field_data.append(row)
        
        # æŒ‰é‡è¦æ€§æ’åº
        field_data.sort(key=lambda x: (x['é‡è¦æ€§'] != 'ğŸŒŸ é‡è¦', x['æ¬„ä½åç¨±']))
        
        field_df = pd.DataFrame(field_data)
        print(field_df.to_string(index=False))
    
    # 4. çµ±è¨ˆæ‘˜è¦
    print(f"\nğŸ“Š ç¸½è¨ˆçµ±è¨ˆ:")
    print(f"  â€¢ ç¸½è³‡æ–™ç­†æ•¸: {sum(analysis[dt]['count'] for dt in ['session', 'record', 'lap'])} ç­†")
    print(f"  â€¢ Session æ¬„ä½: {len(analysis['session']['fields'])} å€‹")
    print(f"  â€¢ Record æ¬„ä½: {len(analysis['record']['fields'])} å€‹")
    print(f"  â€¢ Lap æ¬„ä½: {len(analysis['lap']['fields'])} å€‹")
    print(f"  â€¢ ç¸½æ¬„ä½æ•¸ (å»é‡): {len(set().union(*[analysis[dt]['fields'] for dt in ['session', 'record', 'lap']]))} å€‹")


def export_to_csv(analysis, output_dir="./"):
    """åŒ¯å‡ºåˆ†æçµæœåˆ° CSV æª”æ¡ˆ"""
    
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    print(f"\nğŸ’¾ åŒ¯å‡ºåˆ†æçµæœåˆ° CSV æª”æ¡ˆ...")
    
    # åŒ¯å‡ºå„å€‹æ•¸æ“šé¡å‹çš„æ¬„ä½è©³ç´°è³‡è¨Š
    for data_type in ['session', 'record', 'lap']:
        field_data = []
        for field_name in analysis[data_type]['fields']:
            field_info = analysis[data_type]['field_details'][field_name]
            field_data.append(field_info)
        
        if field_data:
            df = pd.DataFrame(field_data)
            csv_file = output_dir / f"fit_{data_type}_fields.csv"
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"  âœ… {data_type.upper()} æ¬„ä½: {csv_file}")
    
    # åŒ¯å‡ºæ¦‚è¦½è¡¨
    overview_data = []
    for data_type in ['session', 'record', 'lap']:
        overview_data.append({
            'data_type': data_type,
            'count': analysis[data_type]['count'],
            'field_count': len(analysis[data_type]['fields'])
        })
    
    overview_df = pd.DataFrame(overview_data)
    overview_csv = output_dir / "fit_overview.csv"
    overview_df.to_csv(overview_csv, index=False, encoding='utf-8-sig')
    print(f"  âœ… æ¦‚è¦½è¡¨: {overview_csv}")


def main():
    """ä¸»å‡½æ•¸"""
    
    # FIT æª”æ¡ˆè·¯å¾‘
    fit_file_path = '/home/aiuser/codetrekking/storage/garmin/example@gmail.com/activities/19329066809_ACTIVITY.fit'
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not Path(fit_file_path).exists():
        print(f"âŒ æ‰¾ä¸åˆ° FIT æª”æ¡ˆ: {fit_file_path}")
        return
    
    try:
        # åˆ†æ FIT æª”æ¡ˆ
        analysis = analyze_fit_file(fit_file_path)
        
        # å‰µå»ºæ‘˜è¦è¡¨æ ¼
        create_summary_tables(analysis)
        
        # åŒ¯å‡º CSV
        export_to_csv(analysis, "./fit_analysis_output")
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()